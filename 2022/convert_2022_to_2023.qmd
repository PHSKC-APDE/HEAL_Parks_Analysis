---
title: "HEAL Parks 2022 Conversion"
author: "Ronald Buie"
date-modified: "`r Sys.Date()`"

format: 
  pdf:
    toc: true
    number-sections: true
    df-print: kable
    fig-height: 12
    fig-width: 16
execute: 
  echo: false
  warning: false
  output: false
---

#outstanding questions for Seth

# Front Matter

This document outlines procedures and technical details for the integration of data from 2022 HEAL Parks studies to align with 2023 and onward data. The code contained in this script reads prepared data and reformats it to the 2023 standard.

For general information about the project please review the [git](https://github.com/PHSKC-APDE/HEAL_Parks_Analysis) or contact [Seth Schromen-Wawrin](seth.schromen-wawrin@kingcounty.gov) or [Ronald Buie](rbuie@kingcounty.gov)

# Preparing 2022 Data

```{r define constant and environment variables}
# First check if pacman is installed. If not, install it.
if(!"pacman" %in% installed.packages()) {
  install.packages("pacman")
}


# load and install packages using pacman. 
# Pacman will install and load missing packages.
pacman::p_load(data.table, #data structure and analytics framework used throughout
               doParallel,  #parallalize loops, including geography calculation
               flextable, #generate pretty tables in word
               ggplot2, #create pretty charts
               here,  #simplify calls to local directory
               jsonlite, #parse json results
               kableExtra, #kable extension used to generate pretty output
               kcparcelpop,
               officer, #generate word docs
               openxlsx2, #read xlsx files
               RCurl, #prepare and parse json/API querries
               readxl,
               scales, #format ggplot2 axes
               sf, #create spatial objects around long and lat
               spatagg, #geospatial maping for populations
               treemapify, #generate treemaps in ggplot
               utils #modify directory and file structures
               )
               

library(rads) #access apde data

REBUILDACTIVITYTABLE <- TRUE
REBUILDANALYSISSET <- TRUE
RECALCULATEPOPULATIONS <- FALSE
```

2022 data were provided via email by Seth. APDE stores a copy of these and all data in the [DPH -APDEWork:ParkOBservationStudies library/2022 Annual Study/inputs](https://kc1.sharepoint.com/teams/DPH-APDEWork/ParkObservationStudies/Forms/AllItems.aspx)

In order to run this script, you should copy the 2022 Annual Study/inputs folder into the 2022 folder of the HEAL_Parks_Analysis repository, and run this quarto file.

```{r check for data}
library(here)
if(!dir.exists(here("./2022/inputs"))) {
  stop("data not staged, please prepare data as instructred, or reach out to Ronald Buie for help.")
}
```

# Load available 2022 data

timestamps are not uniform across files. currently ignoring these to work on aligning other data.

```{r}


if( !(file.exists(here("2022/local_only/SOPARCAnalysisSet.csv"))) | REBUILDANALYSISSET){
  for(file in dir(here("./2022/inputs/observations"), include.dirs = T, full.names = T)) {
    message(paste("processing", file))
    for(sheet in excel_sheets(file)) {
      if(endsWith(sheet, "2022")){
  
        message(paste("adding sheet:", sheet))
        OldSheet <- as.data.table(read_xlsx(file, sheet = sheet))#, col_types =  c(rep("guess", 6), "text", rep("guess",47))))
        #OldSheet[,"Start Time" := NULL]
        OldSheet$`Start Time` <- format(OldSheet$`Start Time`, format = "%H:%M")
        OldSheet$`Start Time` <- format(OldSheet$`Start Time`, format = "%H:%M")
        OldSheet$`Start Time` <- trimws(ifelse(grepl(":", OldSheet$`Start Time`), gsub("^0","",OldSheet$`Start Time`), gsub("(.{2})$", "\\2:\\1", OldSheet$`Start Time`)))
        
        if(exists("OldDT")) {
          #check name matches before merging
          if(any(!(names(OldSheet) %in% names(OldDT)))){
            warning("missmatch names found attempting patch based on column order: \n")
            #message(paste("the following columns will be renamed",list(names(OldSheet)[!(names(OldSheet) %in% names(OldDT))]),"\n"))
            #message(paste("the new names will be",list(names(OldDT)[!(names(OldSheet) %in% names(OldDT))]), "\n"))
            names(OldSheet)[!(names(OldSheet) %in% names(OldDT))] <- names(OldDT)[!(names(OldSheet) %in% names(OldDT))]
          }
          OldDT <- rbind(OldDT, OldSheet)
        } else {
          OldDT <- OldSheet
        }
      } else {
              message(paste("skipping sheet:", sheet))
      }
    }
    
  
  }
  
  
  
  remove(OldSheet)
  remove(file)
  remove(sheet)
}
```

```{r cleaning varibales data}

if( !(file.exists(here("2022/local_only/SOPARCAnalysisSet.csv"))) | REBUILDANALYSISSET){
  # removing (too) empty observations
  OldDT <- OldDT[!is.na(`Target #`),]
  
  
  # many park names need to be corrected and cleaned
  OldDT[Park == "Brighten Playfield ​",]$Park <- "Brighton Playfield"
  OldDT[Park == "Cascade View Community Park ​" | Park == "Cascade View",]$Park <- "Cascade View Community Park"
  OldDT[Park == "Marra Desimone Park ​",]$Park <- "Marra Desimone Park"
  OldDT[Park == "Midway Park ​",]$Park <-  "Midway Park"
  OldDT[Park == "Moshier Park ​",]$Park <- "Moshier Memorial Park"
  OldDT[Park == "Puget Sound Park  ​",]$Park <- "Puget Sound Park"
  OldDT[Park == "Roxhill Park ​",]$Park <- "Roxhill Park"
  OldDT[Park == "Steel Lake Park (south) ​",]$Park <- "Steel Lake Park"
  OldDT[Park == "Steve Cox Memorial Park ​",]$Park <- "Steve Cox Playfield"
  OldDT[Park == "Tukwila Community Center ​" | Park == "Tukwilla Community C",]$Park <- "Tukwila Community Center"
  
  
  # add ID
  OldDT$record_id <- 1:nrow(OldDT)
  
  # fixing missmatched period names
  OldDT[Period == "lunch"]$Period <- "Lunch"
  OldDT[Period == "morning"]$Period <- "Morning"
  OldDT[Period == "AfterNoon"]$Period <- "Afternoon"
  
  #simplifying activity names
}
```

# Create 2022 SOPARCAnalysis Set

```{r}
if( !(file.exists(here("2022/local_only/SOPARCAnalysisSet.csv"))) | REBUILDANALYSISSET){
                           

  SOPARCActivities <- data.table()


  ParkData <- read_xlsx(here("2022/inputs/Parks_MASTER.xlsx"))

  # c("park_name_full",	"park_name",	"record_id",	"redcap_survey_identifier",	"park_scan_data_collection_timestamp",	"obs_initial",	"start_time",	"tar_area",	"sub_area",	"accessible",	"usable",	"lit",	"occupied",	"supervised",	"organized",	"equipped",	"num_child_prim",	"num_child_snd",	"num_child_spec",	"num_teen_prim",	"num_teen_snd",	"num_teen_spec",	"num_adult_prim",	"num_adult_snd",	"num_adult_spec",	"num_senior_prim",	"num_senior_snd",	"num_senior_spec",	"prim_act_name",	"prim_act_other",	"yesno_snd",	"snd_act_name",	"other_act_snd",	"yesno_spec",	"spec_act_name",	"other_act_spec",	"comments",	"park_scan_data_collection_complete",	"timestampPOSIX",	"datePOSIX",	"day",	"month",	"weekend",	"periodBasedOnSequence",	"dayNumberBasedOnSequence",	"period",	"Park", "Address",	"City",	"Zip",	"Neighborhood",	"Images",	"Tract",	"Latitude",	"Longitude",	"Equity Score Priority", 	"Planned park changes?",	"Notes",	"censusYear",	"populationHalfMile",	"studyStartDate",	"studyDescription",	"study_count")


  
  OldDT.ParkData <- merge(OldDT, ParkData, by.x = "Park", by.y = "Park Name", all.x = T)
  
  park_name_full <- OldDT.ParkData$Park
  park_name <- OldDT.ParkData$`REDCap Name`
  record_id <- OldDT.ParkData$record_id
  redcap_survey_identifier <- NA
  park_scan_data_collection_timestamp <- NA
  obs_initial <- OldDT.ParkData$Initials
  
  SOPARCAnalysisSet <- OldDT.ParkData[, .(park_name_full = Park,
                                          park_name = `REDCap Name`,
                                          record_id,
                                          redcap_survey_identifier = NA,
                                          park_scan_data_collection_timestamp = NA,
                                          obs_initial = Initials,
                                          start_time = NA,
                                          tar_area = `Target #`,
                                          sub_area = Subarea,
                                          accessible = Acc,
                                          usable = Use,
                                          lit = Lit,
                                          occupied = Occ,
                                          supervised = Sup,
                                          organized = Org,
                                          equipped = Equ,
                                          num_child_prim = Youth...18,
                                          num_child_snd = Youth...31,
                                          num_child_spec = Youth...44,
                                          num_teen_prim = NA,
                                          num_teen_snd = NA,
                                          num_teen_spec = NA,
                                          num_adult_prim = Adu...19,
                                          num_adult_snd = Adu...32,
                                          num_adult_spec = Adu...45,
                                          num_senior_prim = Sen...20,
                                          num_senior_snd = Sen...33,
                                          num_senior_spec = Sen...46,
                                          prim_act_name = ifelse(is.na(Activity1), NA, paste(toupper(substr( Activity1, 1,1)), tolower(substr( Activity1, 2, nchar(Activity1))), sep = "")),
                                          prim_act_other = NA,
                                          yesno_snd = ifelse(is.na(Activity2), "No","Yes"),
                                          snd_act_name = ifelse(is.na(Activity2), NA, paste(toupper(substr( Activity2, 1,1)), tolower(substr( Activity2, 2, nchar(Activity2))), sep = "")),
                                          snd_act_other = NA,
                                          yesno_spec = ifelse(is.na(Activity), "No","Yes"),
                                          spec_act_name = ifelse(is.na(Activity), NA, paste(toupper(substr( Activity, 1,1)), tolower(substr( Activity, 2, nchar(Activity))), sep = "")),
                                          spec_act_other = NA,
                                          comments = Comment,
                                          park_scan_data_collection_complete = "Complete",
                                          timestampPOSIX = NA,
                                          datePOSIX = as.POSIXct(Date, "", "%m/%d/%Y"),
                                          #datePOSIX = Date,
                                          day = NA,
                                          month = NA,
                                          weekend = NA,
                                          periodBasedOnSequence = "",
                                          dayNumberBasedOnSequence = NA,
                                          period = Period,
                                          `Park Address`,
                                          City,
                                          Zip,
                                          Neighborhood,
                                          Images,
                                          Tract,
                                          Latitude,
                                          Longitude,
                                          `Equity Score Priority`,
                                          `Planned park changes?`,
                                          Notes,
                                          censusYear = 2022,
                                          studyStartDate = "7/1/2022",
                                          studyDescription = "2022 annual study",
                                          study_count = 1)]
  
  SOPARCAnalysisSet <- as.data.table(SOPARCAnalysisSet)
  #load corrections
  #Corrections <- fread("./inputs/ERRORED_OBSERVATIONS-correctionsv2.csv")
  #SOPARCAnalysisSet <- SOPARCAnalysisSet[!(record_id %in% Corrections$record_id),]
  #Corrections$datePOSIX <- as.POSIXct(Corrections$datePOSIX, "", "%m/%d/%Y")
  #SOPARCAnalysisSet[,40]
  #Corrections[,40]
  #SOPARCAnalysisSet <- rbind(SOPARCAnalysisSet, Corrections)
  
  #assigning period based on sequence
  #debugging, error catcher...
  if(exists("catcher")) {
    remove(catcher)
  }
  
  
  for(park in unique(SOPARCAnalysisSet$park_name)) {
    for(date in unique(SOPARCAnalysisSet[park_name == park,datePOSIX])) {
      for(targetArea in unique(SOPARCAnalysisSet[park_name == park & datePOSIX == date, tar_area]))
        for(selected_period in unique(SOPARCAnalysisSet[park_name == park & datePOSIX == date & tar_area == targetArea, period])) {
          if(nrow(SOPARCAnalysisSet[park_name == park & datePOSIX == date & tar_area == targetArea & period == selected_period,]) != 2) {
            warning("there should only be 2 rows here. temporary path is to remove extras or duplicate singleton")
            
            if(!exists("catcher")) {
              catcher <- SOPARCAnalysisSet[park_name == park & datePOSIX == date & tar_area == targetArea & period == selected_period,]
            } else {
              catcher <- rbind(SOPARCAnalysisSet[park_name == park & datePOSIX == date & tar_area == targetArea & period == selected_period,], catcher)
            } 
          }
        }
    }
    
  }
  if(exists("catcher")) {
      write.csv(catcher, here("2022/outputs/data-metadata/ERRORED_OBSERVATIONS.csv"), row.names = FALSE)
  } else {
    #create period based on sequence
      for(park in unique(SOPARCAnalysisSet$park_name)) {
        for(date in unique(SOPARCAnalysisSet[park_name == park,datePOSIX])) {
          for(targetArea in unique(SOPARCAnalysisSet[park_name == park & datePOSIX == date, tar_area]))
            for(selected_period in unique(SOPARCAnalysisSet[park_name == park & datePOSIX == date & tar_area == targetArea, period])) {
              if(selected_period == "Morning") {
                    SOPARCAnalysisSet[park_name == park & datePOSIX == date & tar_area == targetArea & period == selected_period,]$periodBasedOnSequence <- c("Morning1", "Morning2")
              }
              if(selected_period == "Lunch") {
                SOPARCAnalysisSet[park_name == park & datePOSIX == date & tar_area == targetArea & period == selected_period,]$periodBasedOnSequence <- c("Lunch1", "Lunch2")
              }
              if(selected_period == "Afternoon") {
                SOPARCAnalysisSet[park_name == park & datePOSIX == date & tar_area == targetArea & period == selected_period,]$periodBasedOnSequence <- c("Afternoon1", "Afternoon2")
              }
              if(selected_period == "Evening") {
                SOPARCAnalysisSet[park_name == park & datePOSIX == date & tar_area == targetArea & period == selected_period,]$periodBasedOnSequence <- c("Evening1", "Evening2")
              }
            }
          }
        }
    }
        

  write.csv(SOPARCAnalysisSet, here("2022/local_only/SOPARCAnalysisSetExtract.csv"), row.names = FALSE)
} else {
  SOPARCAnalysisSet <-  fread(here("2022/local_only/SOPARCAnalysisSetExtract.csv"))
}

```

```{r calculate populations in half mile radius}
skip <- FALSE
if(file.exists(here("2022/local_only/Park_Populations.csv"))){
  ParkPopulationTable <- fread(here("2022/local_only/Park_Populations.csv"))
  if("PopulationHalfMile" %in% names(ParkPopulationTable) &
     all(unique(SOPARCAnalysisSet$park_name_full) %in% ParkPopulationTable[censusYear == 2022,]$park_name_full)) {
    skip <- TRUE #yay no need to calculate 
  }
}
if(!skip | RECALCULATEPOPULATIONS) {
  
  crsString <- "EPSG:2926" #preferred coordinate reference system for WA
  
  ParkGeos <- unique.data.frame(SOPARCAnalysisSet[,.("park" = park_name_full, "long" = Longitude, "lat" = Latitude)]) #create a prototype data frame for holding our geometry. This has the raw lat long data
  
  ParkGeos <- st_as_sf(x = ParkGeos,coords = c("long","lat"), crs = "EPSG:4326") #turn teh raw data into a geometry using crs 2926 (this is one recomended for WA)
  ParkGeos <- st_transform(ParkGeos, st_crs(crsString))
  ParkGeos <- st_buffer(ParkGeos, units::set_units(0.5, mile)) # units::set_units is intelligent about types of units so you can specify "mile". st_buffer will create a perimeter of the provided units.
  
  BlockShapes <- st_read("//dphcifs/APDE-CDIP/Shapefiles/Census_2020/block/kc_block.shp") 
  BlockShapes <- st_transform(BlockShapes, st_crs(crsString)) #conform to same crs
  
  # ggplot() + geom_sf(data = BlockShapes, fill = NA) +
  #   geom_sf(data = ParkGeos, fill = NA, color = 'purple')
  
  #get KC population estimates. Note, if a radius desired extends outside the county, then need to expand. Will greatly slow down calculations
  #if not saved, pull and save. Otherwise, load from save
  if(file.exists(here("2022/local_only/KCPops.csv"))) {
    KCPops <- read.csv(here("2022/local_only/KCPops.csv"))
  } else {
    KCPops <- get_population(geo_type = "blk", kingco = T, year = 2022, ages = 0:100)
    write.csv(x = KCPops,file =  here("./2022/local_only/KCPops.csv"), row.names = F)
  }
  
  #Create data frame for final results
  ParkPopulationTable <- data.table("park_name_full" = unique(SOPARCAnalysisSet$park_name_full), "censusYear" = 2022, "PopulationHalfMile" = 0)
  
#  if(PARALLEL_PROCESS){
#  numCores <- detectCores()-1
#  cl <- makeCluster(numCores, outfile = "")
#  registerDoParallel(cl)
#  ChildParkPopulationTable[parkNameFull == ParkGeos[rowIndex,]$park, ]$childPopulationHalfMile <- foreach (rowIndex = 1:nrow(ParkGeos), #.combine=rbind) %dopar% {
#    CW <- create_xwalk(BlockShapes, ParkGeos[rowIndex,], "GEOID20", "park",min_overlap = 0.00001)
#    CWPop <- merge(CW, KCPops, by.x = "source_id", by.y = "geo_id")
#    weightedPop <- sum(CWPop$s2t_fraction * CWPop$pop)
#    weightedPop 
#  }
#  stopCluster(cl)
#} else {
  #loop through parks and generate crosswalk for each park.
  for(rowIndex in 1:nrow(ParkGeos)) {
    CW <- create_xwalk(BlockShapes, ParkGeos[rowIndex,], "GEOID20", "park",min_overlap = 0.00001)
    CWPop <- merge(CW, KCPops, by.x = "source_id", by.y = "geo_id")
    weightedPop <- sum(CWPop$s2t_fraction * CWPop$pop)
    
    ParkPopulationTable[park_name_full == ParkGeos[rowIndex,]$park, ]$PopulationHalfMile <- weightedPop 
    #print(paste0("Completed #", rowIndex," (",ParkGeos[rowIndex,park],")"))
    print(paste0("Completed ", rowIndex, " of ", nrow(ParkGeos)))
  }
#}
  
  write.csv(ParkPopulationTable ,here("2022/local_only/Park_Populations.csv"), row.names = F)
}

  
SOPARCAnalysisSet <- merge(SOPARCAnalysisSet, ParkPopulationTable, by = "park_name_full")
write.csv(SOPARCAnalysisSet ,here("2022/outputs/data-metadata/SOPARCAnalysisSet.csv"), row.names = F)
```

# Create 2022 SOPARC Analysis Set

# Create 2022 SOPARCActivities.csv

```{r process SOPARCActivities}

if( !(file.exists(here("2022/local_only/SOPARCActivities.csv"))) | REBUILDACTIVITYTABLE){
# SOPARCActivities <- data.table("record_id" = SOPARCObservations[prim_act_name != "",]$record_id, 
#                                "record_id_aggregated" = SOPARCObservations[prim_act_name != "",]$record_id, 
#                                "activity" = "", 
#                                "children" = 0, 
#                                "teen" = 0, 
#                                "adult" = 0, 
#                                "senior" = 0)
#                                
#                                
#                                
  
  SOPARCActivities <- data.table()

  for(id in SOPARCAnalysisSet[prim_act_name != "",]$record_id) {

      # SOPARCActivities[record_id == id, `:=`(activity = ifelse(SOPARCObservations[record_id == id, ]$prim_act_name == "Other", SOPARCObservations[record_id == id, ]$prim_act_other, SOPARCObservations[record_id == id, ]$prim_act_name),
      #                                        children = SOPARCObservations[record_id == id, ]$num_child_prim, 
      #                                        teen = SOPARCObservations[record_id == id, ]$num_teen_prim, 
      #                                        adult = SOPARCObservations[record_id == id, ]$num_adult_prim, 
      #                                        senior = SOPARCObservations[record_id == id, ]$num_senior_prim)] 
    
    DT <- SOPARCAnalysisSet[record_id == id, .(record_id = id,
                                                record_id_aggregated = id,
                                          activity = ifelse(prim_act_name == "Other", prim_act_other, prim_act_name),
                                          children = num_child_prim, 
                                          teen = num_teen_prim, 
                                          adult = num_adult_prim, 
                                          senior = num_senior_prim)]
    
    SOPARCActivities <- rbindlist(list(SOPARCActivities, DT))
    
    if(SOPARCAnalysisSet[record_id == id,]$yesno_snd == "Yes") {
      # SOPARCActivities[record_id == id, `:=`(activity = ifelse(SOPARCObservations[record_id == id, ]$snd_act_name == "Other", SOPARCObservations[record_id == id, ]$other_act_snd, SOPARCObservations[record_id == id, ]$snd_act_name),
      #                                        children = SOPARCObservations[record_id == id, ]$num_child_snd, 
      #                                        teen = SOPARCObservations[record_id == id, ]$num_teen_snd, 
      #                                        adult = SOPARCObservations[record_id == id, ]$num_adult_snd, 
      #                                        senior = SOPARCObservations[record_id == id, ]$num_senior_snd)] 
      
      DT <- SOPARCAnalysisSet[record_id == id, .(record_id = id,
                                                  record_id_aggregated = id,
                                      activity = ifelse(snd_act_name == "Other", other_act_snd, snd_act_name),
                                      children = num_child_snd, 
                                      teen = num_teen_snd, 
                                      adult = num_adult_snd, 
                                      senior = num_senior_snd)]
      SOPARCActivities <- rbindlist(list(SOPARCActivities, DT))
    }
    if(SOPARCAnalysisSet[record_id == id,]$yesno_spec == "Yes") {
      # SOPARCActivities[record_id == id, `:=`(activity = ifelse(SOPARCObservations[record_id == id, ]$spec_act_name == "Other", SOPARCObservations[record_id == id, ]$other_act_spec, SOPARCObservations[record_id == id, ]$spec_act_name),
      #                                        children = SOPARCObservations[record_id == id, ]$num_child_spec, 
      #                                        teen = SOPARCObservations[record_id == id, ]$num_teen_spec, 
      #                                        adult = SOPARCObservations[record_id == id, ]$num_adult_spec, 
      #                                        senior = SOPARCObservations[record_id == id, ]$num_senior_spec)] 
      DT <- SOPARCAnalysisSet[record_id == id, .(record_id = id,
                                                  record_id_aggregated = id,
                                activity = ifelse(spec_act_name == "Other", other_act_spec, spec_act_name),
                                children = num_child_spec, 
                                teen = num_teen_spec, 
                                adult = num_adult_spec, 
                                senior = num_senior_spec)]
      SOPARCActivities <- rbindlist(list(SOPARCActivities, DT))
    }
  }
  write.csv(SOPARCActivities, here("2022/local_only/SOPARCActivities.csv"), row.names = FALSE)
  write.csv(SOPARCActivities, here("2022/outputs/data-metadata/SOPARCActivities.csv"), row.names = FALSE)
} else {
  SOPARCActivities <-  fread(here("2022/local_only/SOPARCActivities.csv"))
}
```

# Create 2022 SOPARCActivitiesExpanded.csv

```{r process SOPARCActivitiesExpanded}
# c("record_id_aggregated",	"record_id", "activity",	"children",	"teen",	"adult",	"senior",	"park_name_full",	"period",	"target_area",	"datePOSIX")

SOPARCActivitiesExpanded <- merge(SOPARCActivities, SOPARCAnalysisSet[,.(record_id,	park_name_full,	period,	tar_area,	datePOSIX)], by = "record_id", all.x = TRUE)

write.csv(SOPARCActivitiesExpanded, here("2022/outputs/data-metadata/SOPARCActivitiesExpanded.csv"), row.names = FALSE)
```

# Create 2022 SOPARCAnalysisSetAggregatedPeriods

```{r}
c("park_name_full",	"park_name",	"tar_area",	"dayNumberBasedOnSequence",	"period",	"datePOSIX",	"day",	"month",	"weekend",	"accessible",	"usable",	"lit",	"occupied",	"supervised",	"organized",	"equipped",	"num_child_prim",	"num_child_snd",	"num_child_spec",	"num_teen_prim",	"num_teen_snd",	"num_teen_spec",	"num_adult_prim",	"num_adult_snd",	"num_adult_spec",	"num_senior_prim",	"num_senior_snd",	"num_senior_spec",	"Park Address",	"City",	"Zip",	"Neighborhood",	"Images",	"Tract",	"Latitude",	"Longitude",	"Equity Score Priority", "Planned park changes?",	"Notes",	"censusYear",	"populationHalfMile",	"studyStartDate",	"studyDescription",	"study_count")
SOPARCtoAggregate <-copy(SOPARCAnalysisSet)

#create single periodname for aggregating first and second of each period using sequence periods
SOPARCtoAggregate[periodBasedOnSequence %in% c("morning1","morning2"), period := "Morning"]
SOPARCtoAggregate[periodBasedOnSequence %in% c("lunch1","lunch2"), period := "Lunch"]
SOPARCtoAggregate[periodBasedOnSequence %in% c("afternoon1","afternoon2"), period := "Afternoon"]
SOPARCtoAggregate[periodBasedOnSequence %in% c("evening1","evening2"), period := "Evening"]

SOPARCtoAggregate$period <-  factor(SOPARCtoAggregate$period, level = c("Morning","Lunch","Afternoon","Evening"))


SOPARCAggregated <- SOPARCtoAggregate[,
                                      .("accessible" = ifelse(any(accessible %in% "Yes"), "Yes", "No"),
                                        "usable" = ifelse(any(usable %in% "Yes"), "Yes", "No"),
                                        "lit" = ifelse(any(lit %in% "Yes"), "Yes", "No"),
                                        "occupied" = ifelse(any(occupied %in% "Yes"), "Yes", "No"),
                                        "supervised" = ifelse(any(supervised %in% "Yes"), "Yes", "No"),
                                        "organized" = ifelse(any(organized %in% "Yes"), "Yes", "No"),
                                        "equipped" = ifelse(any(organized %in% "Yes"), "Yes", "No"),
                                        "num_child_prim" = ceiling(mean(num_child_prim, na.rm = T, )),
                                        "num_child_snd" = ceiling(mean(num_child_snd, na.rm = T)),
                                        "num_child_spec" = ceiling(mean(num_child_spec, na.rm = T)),
                                        "num_teen_prim"= ceiling(mean(num_teen_prim, na.rm = T)),
                                        "num_teen_snd" = ceiling(mean(num_teen_snd, na.rm = T)),
                                        "num_teen_spec" = ceiling(mean(num_teen_spec, na.rm = T)),
                                        "num_adult_prim" = ceiling(mean(num_adult_prim, na.rm = T)),
                                        "num_adult_snd" = ceiling(mean(num_adult_snd, na.rm = T)),
                                        "num_adult_spec" = ceiling(mean(num_adult_spec, na.rm = T)),
                                        "num_senior_prim" = ceiling(mean(num_senior_prim, na.rm = T)),
                                        "num_senior_snd" = ceiling(mean(num_senior_snd, na.rm = T)),
                                        "num_senior_spec" = ceiling(mean(num_senior_spec, na.rm = T))), 
                                      by = .(park_name, tar_area, dayNumberBasedOnSequence, period, datePOSIX, day, month, weekend )]


write.csv(SOPARCtoAggregate, here("2022/outputs/data-metadata/SOPARCAnalysisSetAggregatedPeriods.csv"), row.names = FALSE)


```

```{r add metadata and save analysis sets}


#consider if this is necessary, sampled from 2023 work

##generate study count and append this to aggregated and non aggregated analysis ready sets
#SOPARCtoAggregate <- merge(SOPARCtoAggregate, ParksStudyRecord[,.("study_count" = .N) , by = parkName], by.x = "park_name_full", by.y = "parkName", all.x = T)
#SOPARCAggregated <- merge(SOPARCAggregated, ParksStudyRecord[,.("study_count" = .N) , by = parkName], by.x = "park_name_full", by.y = "parkName", all.x = T)


```

# Analysis Notes

## Missing "child" and "teen" counts

The 2022 data counted all non adult or elder presenting persons as "youth". This creates a challenge in comparing to later years which divide apparant minors into "child" and "teen". Two strategies have been proposed for harmonizing across years where analsis of age group is included:

-   aggregate later years to "youth". Undesirable because current metric development is focused on children and playgrounds.
-   calculate the proportion of children and teens observed in a given park for the metric for later years, and use this to re-weight the youth from 2022 into children and teens in the same proportion. Requires there to be later years of the same park, which might not always be available.
